{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from helpers.preprocessing import PreProcessing\n",
    "from sklearn.ensemble import GradientBoostingClassifier, VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proprocessing and Save Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"data/symp.xlsx\")\n",
    "symptoms = data['q_11'].to_numpy()\n",
    "\n",
    "processing = PreProcessing()\n",
    "symptoms_preprocess = processing.transform(symptoms)\n",
    "symptoms_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modeling/vectorizer.save']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(\n",
    "    max_df=len(symptoms_preprocess), \n",
    "    min_df=0,\n",
    "    decode_error='ignore',\n",
    "    binary=True\n",
    ")\n",
    "\n",
    "data_vectorizer = pd.DataFrame(\n",
    "    vectorizer.fit_transform(symptoms_preprocess).toarray(), \n",
    "    columns=vectorizer.get_feature_names_out()\n",
    ")\n",
    "\n",
    "data_vectorizer['disorder'] =  pd.read_excel('data/data_klasifikasi.xlsx')['disorder']\n",
    "\n",
    "data_vectorizer.to_csv('data/data_vectorizer.csv', index=False)\n",
    "joblib.dump(vectorizer, 'modeling/vectorizer.save') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/data_vectorizer.csv')\n",
    "\n",
    "target_column = 'disorder'\n",
    "X = data.drop(target_column, axis=1).to_numpy()\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(data[target_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('f1_score',\n",
       "                              GradientBoostingClassifier(learning_rate=0.0801,\n",
       "                                                         max_depth=2,\n",
       "                                                         min_samples_leaf=3,\n",
       "                                                         min_samples_split=8)),\n",
       "                             ('recall',\n",
       "                              GradientBoostingClassifier(learning_rate=0.1401,\n",
       "                                                         max_depth=2,\n",
       "                                                         min_samples_leaf=3,\n",
       "                                                         min_samples_split=8,\n",
       "                                                         n_estimators=400)),\n",
       "                             ('precision',\n",
       "                              GradientBoostingClassifier(learning_rate=0.0201,\n",
       "                                                         max_depth=2,\n",
       "                                                         min_samples_leaf=3,\n",
       "                                                         min_samples_split=8,\n",
       "                                                         n_estimators=300)),\n",
       "                             ('accuracy',\n",
       "                              GradientBoostingClassifier(learning_rate=0.040100000000000004,\n",
       "                                                         min_samples_leaf=5,\n",
       "                                                         min_samples_split=6))])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob(\"report/*\")\n",
    "report = pd.concat([pd.read_csv(file, index_col=0) for file in files]).reset_index(drop=True)\n",
    "report.columns = report.columns.str.replace('_test', '')\n",
    "\n",
    "selected_columns = ['clf_name', 'params', 'mean_recall', 'mean_precision', 'mean_f1-score', 'mean_accuracy']\n",
    "best_recall = report.sort_values(['mean_recall', 'mean_f1-score'], ascending=[False, False])[selected_columns].head().copy()\n",
    "best_f1 = report.sort_values('mean_f1-score', ascending=False)[selected_columns].head().copy()\n",
    "best_accuracy = report.sort_values('mean_accuracy', ascending=False)[selected_columns].head().copy()\n",
    "best_precision = report.sort_values('mean_precision', ascending=False)[selected_columns].head().copy()\n",
    "\n",
    "best_params_f1 = eval(best_f1.iloc[0, 1])\n",
    "best_params_recall = eval(best_recall.iloc[1, 1])\n",
    "best_params_precision = eval(best_precision.iloc[0, 1])\n",
    "best_params_accuracy = eval(best_accuracy.iloc[0, 1])\n",
    "\n",
    "clf1 = GradientBoostingClassifier(**best_params_f1)\n",
    "clf2 = GradientBoostingClassifier(**best_params_recall)\n",
    "clf3 = GradientBoostingClassifier(**best_params_precision)\n",
    "clf4 = GradientBoostingClassifier(**best_params_accuracy)\n",
    "\n",
    "model = VotingClassifier(estimators=[\n",
    "        ('f1_score', clf1), ('recall', clf2), ('precision', clf3), ('accuracy', clf4)], voting='hard')\n",
    "    \n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modeling/decision_tree_model.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save model dan encoder\n",
    "joblib.dump(label_encoder, \"modeling/label_encoder.save\")\n",
    "joblib.dump(model, 'modeling/decision_tree_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to Predict New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 8: expected 46 fields, saw 56\\n'\n",
      "b'Skipping line 8: expected 25 fields, saw 29\\n'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Bipolar'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symptoms = \"I feel very anxious, sometimes I want to suicide\"\n",
    "\n",
    "vectorizer = joblib.load('modeling/vectorizer.save')\n",
    "label_encoder = joblib.load('modeling/label_encoder.save')\n",
    "model = joblib.load('modeling/decision_tree_model.pkl')\n",
    "\n",
    "preprocessing = PreProcessing()\n",
    "symptoms_preprocess = preprocessing.transform(symptoms)\n",
    "\n",
    "X = vectorizer.transform(symptoms_preprocess)\n",
    "prediction = model.predict(X)\n",
    "prediction = label_encoder.inverse_transform(prediction)[0]\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['addict', 'alcohol', 'anger', 'anxious', 'appetite', 'balance',\n",
       "        'breathe', 'bulimia', 'communicate', 'concentrate', 'confuse', 'cry',\n",
       "        'delusion', 'depress', 'digestive', 'distrust', 'dizzy', 'drug', 'eat',\n",
       "        'echolalia', 'emotion', 'empty', 'excess', 'faint', 'fluctuation',\n",
       "        'forget', 'guilt', 'harm', 'hatred', 'headache', 'heartbeat',\n",
       "        'hopeless', 'impulsive', 'insomnia', 'lazy', 'libido', 'lonely', 'mood',\n",
       "        'nausea', 'numb', 'obsessive', 'overreact', 'panic', 'paranoia',\n",
       "        'respond', 'sad', 'scare', 'stress', 'suicide', 'sweat', 'tire',\n",
       "        'trauma', 'tremble', 'violence', 'weight', 'withdrawal', 'worry',\n",
       "        'disorder'],\n",
       "       dtype='object'),\n",
       " 58)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/data_vectorizer.csv')\n",
    "data.columns, len(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['addict', 'alcohol', 'anger', 'anxious', 'appetite', 'balance',\n",
       "        'breathe', 'bulimia', 'communicate', 'concentrate', 'confuse', 'cry',\n",
       "        'delusion', 'depress', 'digestive', 'distrust', 'dizzy', 'drug', 'eat',\n",
       "        'echolalia', 'emotion', 'empty', 'excess', 'faint', 'fluctuation',\n",
       "        'forget', 'guilt', 'harm', 'hatred', 'headache', 'heartbeat',\n",
       "        'hopeless', 'impulsive', 'insomnia', 'lazy', 'libido', 'lonely', 'mood',\n",
       "        'nausea', 'numb', 'obsessive', 'overreact', 'panic', 'paranoia',\n",
       "        'respond', 'sad', 'scare', 'stress', 'suicide', 'sweat', 'tire',\n",
       "        'trauma', 'tremble', 'violence', 'weight', 'withdrawal', 'worry',\n",
       "        'disorder'],\n",
       "       dtype='object'),\n",
       " 58)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = pd.read_excel('data/data_klasifikasi.xlsx')\n",
    "data2.columns, len(data2.columns)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1a96b9fde85eae18f328e26a2214f5533e885c6cdd021089c2c5b6c440d89605"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('metamorphosis-modeling')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
